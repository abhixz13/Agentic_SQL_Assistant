# SQL_Assistant_2: Project Structure & Information Flow

## üìÅ Project Tree Structure

```
SQL_Assistant_2/
‚îú‚îÄ‚îÄ agents/                              # Multi-agent AI system
‚îÇ   ‚îú‚îÄ‚îÄ chart_generator/                 # (Future) Chart generation
‚îÇ   ‚îú‚îÄ‚îÄ coordinator/                     # (Future) Agent coordination
‚îÇ   ‚îú‚îÄ‚îÄ intent_parser/                   # Natural language intent parsing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.py                     # IntentParserAgent
‚îÇ   ‚îú‚îÄ‚îÄ query_executor/                  # SQL execution & validation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.py                     # QueryExecutorAgent
‚îÇ   ‚îú‚îÄ‚îÄ reasoning_agent/                 # Query analysis & correction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py                     # ReasoningAgent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ schema_loader/                   # (Future) Dynamic schema loading
‚îÇ   ‚îú‚îÄ‚îÄ shared/                          # Shared utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retry.py                     # Retry mechanisms
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                   # Common data models
‚îÇ   ‚îú‚îÄ‚îÄ sql_generator/                   # üöÄ Core SQL generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py                     # SQLGeneratorAgent (GPT-3.5)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ few_shot_generator.py        # üéØ Few-shot examples (GPT-4o-mini)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                   # SQL query models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_sql_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ visualization/                   # Data visualization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent.py                     # VisualizationAgent
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ workflow.py                      # üîÑ Main workflow orchestration
‚îú‚îÄ‚îÄ config/                              # Configuration files
‚îú‚îÄ‚îÄ data/                                # Data storage
‚îÇ   ‚îú‚îÄ‚îÄ few_shot_examples/               # üß† Generated SQL examples
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ examples_1912b25c.json      # Intent-aware examples
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ examples_cf08259c.json      # General examples
‚îÇ   ‚îú‚îÄ‚îÄ db.sqlite                        # Test database
‚îÇ   ‚îú‚îÄ‚îÄ product_sales_dataset.csv       # Raw data
‚îÇ   ‚îî‚îÄ‚îÄ product_sales.db                 # Main SQLite database
‚îú‚îÄ‚îÄ docs/                                # Documentation
‚îú‚îÄ‚îÄ Server/                              # Server components
‚îÇ   ‚îî‚îÄ‚îÄ src/core/
‚îÇ       ‚îî‚îÄ‚îÄ intent_parser_tool.py        # Server-side intent parsing
‚îú‚îÄ‚îÄ shared/                              # Shared resources
‚îú‚îÄ‚îÄ tests/                               # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ test_visualization.py
‚îú‚îÄ‚îÄ utils/                               # Utility modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ file_converter.py                # File conversion utilities
‚îÇ   ‚îî‚îÄ‚îÄ token_tracker.py                 # üìä OpenAI token tracking
‚îú‚îÄ‚îÄ gradio_ui.py                         # üåê Main web interface
‚îú‚îÄ‚îÄ main.py                              # CLI entry point
‚îú‚îÄ‚îÄ requirements.txt                     # Python dependencies
‚îî‚îÄ‚îÄ [Documentation Files]               # Various MD files
```

## üîÑ Information Flow: User Query ‚Üí SQL Generation

### Overview
```mermaid
graph TD
    A[üë§ User Query] --> B[üåê Gradio UI]
    B --> C[üß† Intent Parser]
    C --> D[üìä Schema Loader]
    D --> E[üéØ Few-Shot Generator]
    E --> F[‚ö° SQL Generator]
    F --> G[üîç Query Executor]
    G --> H[ü§î Reasoning Agent]
    H --> I[üìà Visualization]
    I --> J[‚úÖ Response to User]
```

### Detailed Step-by-Step Flow

#### 1. üåê **User Interface Layer** (`gradio_ui.py`)
```python
# Entry point: process_natural_language_query()
User Input: "Show me revenue by region"
Chart Type: "bar"
```
**Actions:**
- Receives natural language query
- Initializes token tracker
- Sets up AI workflow components

#### 2. üß† **Intent Parsing** (`agents/intent_parser/agent.py` + `gradio_ui.py`)
```python
# Function: parse_natural_language_to_intent()
Input: "Show me revenue by region"
Output: {
    "action": "aggregate",
    "entity": "product_sales", 
    "params": {
        "column": "total_price",
        "function": "sum",
        "group_by": "region",
        "order_by": null,
        "filters": []
    }
}
```
**Technologies:**
- **OpenAI GPT-3.5-turbo** for intent parsing
- Schema-aware prompting
- Fallback mechanisms for API failures

#### 3. üìä **Schema Loading** (`gradio_ui.py::get_formatted_schema()`)
```python
# Database introspection
Schema Output: {
    "tables": {
        "product_sales": {
            "columns": [
                {"name": "total_price", "type": "REAL", "primary_key": false},
                {"name": "region", "type": "TEXT", "primary_key": false},
                // ... more columns
            ],
            "indexes": [
                {"name": "idx_region", "columns": ["region"]}
            ]
        }
    }
}
```
**Actions:**
- SQLite `PRAGMA` commands for schema extraction
- Column type and constraint detection
- Index information gathering

#### 4. üéØ **Few-Shot Example Generation** (`agents/sql_generator/few_shot_generator.py`)
```python
# Class: FewShotExampleGenerator
Input: schema_info + query_intent
Process: GPT-4o-mini generates context-aware examples
Output: Formatted examples for prompt injection

Example Generated:
"Example: Revenue analysis by region
Thinking Process:
  Step 1: Identify revenue column (total_price)
  Step 2: Group by region dimension  
  Step 3: Sum revenue for each region
SQL: SELECT region, SUM(total_price) FROM product_sales GROUP BY region;"
```
**Key Features:**
- **GPT-4o-mini** for cost-effective example generation
- Intent-aware example selection
- Schema-compliant SQL patterns
- Thinking process documentation

#### 5. ‚ö° **SQL Generation** (`agents/sql_generator/agent.py`)
```python
# Class: SQLGeneratorAgent
Input: intent_data + schema_info + few_shot_examples
Process: GPT-3.5-turbo with enhanced prompting
Output: SQLQuery object

Generated SQL: 
"SELECT region, SUM(total_price) AS total_revenue 
 FROM product_sales 
 GROUP BY region;"

Confidence: 0.9
Metadata: {"complexity": "medium", "estimated_rows": "low"}
```
**Advanced Features:**
- Dynamic few-shot example injection
- Schema validation and auto-correction
- SQL optimization (ORDER BY for LIMIT, etc.)
- Confidence scoring

#### 6. üîç **Query Execution** (`agents/query_executor/agent.py`)
```python
# Class: QueryExecutorAgent
Input: sql_query + database_path
Process: SQLite execution with error handling
Output: ExecutionResult

Result: {
    "data": [
        {"region": "North", "total_revenue": 150000},
        {"region": "South", "total_revenue": 120000},
        // ... more rows
    ],
    "execution_time": 0.023,
    "row_count": 4
}
```
**Error Handling:**
- SQL syntax validation
- Timeout protection
- Resource limit enforcement

#### 7. ü§î **Reasoning & Correction** (`agents/reasoning_agent/agent.py`)
```python
# Class: ReasoningAgent
Input: execution_result + original_intent
Process: Analysis and potential correction
Output: Enhanced result with explanations

If Error Detected:
- Schema mismatch correction
- SQL syntax fixes  
- Alternative query suggestions
```

#### 8. üìà **Visualization** (`agents/visualization/agent.py`)
```python
# Class: VisualizationAgent
Input: query_results + chart_type
Process: Dynamic axis inference + Plotly chart generation
Output: Interactive chart

Chart Config: {
    "type": "bar",
    "x_axis": "region", 
    "y_axis": "total_revenue",
    "title": "Revenue by Region"
}
```

#### 9. üìä **Response Assembly** (`gradio_ui.py`)
```python
# Final assembly in process_natural_language_query()
Components:
- DataFrame: Query results
- Plot: Interactive visualization  
- Explanation: Detailed breakdown

Explanation Includes:
- Intent analysis
- Generated SQL (with corrections if any)
- Model confidence & metadata
- Execution metrics (time, rows, tokens)
- Query plan analysis
```

## üîß Key Technical Components

### üß† **AI Models Used**
| Component | Model | Purpose |
|-----------|-------|---------|
| Intent Parsing | GPT-3.5-turbo | Natural language ‚Üí structured intent |
| Few-Shot Generation | GPT-4o-mini | Context-aware SQL examples |
| SQL Generation | GPT-3.5-turbo | Intent + schema ‚Üí SQL query |

### üìä **Data Flow Architecture**
```
[User Query] 
    ‚Üì 
[Intent Parser] ‚Üí {action, entity, params}
    ‚Üì
[Schema Loader] ‚Üí {tables, columns, types, indexes}
    ‚Üì
[Few-Shot Generator] ‚Üí Context-aware examples
    ‚Üì
[SQL Generator] ‚Üí Validated SQL + metadata
    ‚Üì
[Query Executor] ‚Üí Result data + performance metrics
    ‚Üì
[Visualization] ‚Üí Interactive charts
    ‚Üì
[Response] ‚Üí Complete answer with explanations
```

### üéØ **Enhanced Features**

#### **Intent-Aware Few-Shot Learning**
- Examples tailored to current query type
- Progressive complexity demonstration
- Schema-compliant patterns

#### **Token Optimization**
- Selective schema context (relevant tables only)
- Cached example generation
- Efficient prompt engineering

#### **Error Recovery**
- Automatic SQL correction
- Schema mismatch detection
- Fallback query generation

#### **Performance Monitoring**
- Token usage tracking
- Execution time measurement
- Confidence scoring

## üöÄ **Execution Flow Summary**

1. **User enters natural language query** in Gradio UI
2. **Intent parser** extracts structured intent using GPT-3.5
3. **Schema loader** provides database structure context
4. **Few-shot generator** creates relevant examples using GPT-4o-mini
5. **SQL generator** produces optimized SQL using GPT-3.5 + examples
6. **Query executor** runs SQL against SQLite database
7. **Reasoning agent** validates and potentially corrects results
8. **Visualization agent** creates interactive charts
9. **Response assembled** with data, charts, and detailed explanations

This architecture ensures **high accuracy**, **cost efficiency**, and **robust error handling** while providing **transparent explanations** of the entire process.
